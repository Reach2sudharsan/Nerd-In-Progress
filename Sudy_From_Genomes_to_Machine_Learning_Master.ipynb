{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sudy_From_Genomes_to_Machine_Learning_Master.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i46RCXx_hCk9"
      },
      "source": [
        "# Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0doqIOEhJBC"
      },
      "source": [
        "In this colab, you will:\n",
        "*   Learn how to clean up and preprocess genome data\n",
        "*   Convert genomic data into a feature matrix\n",
        "*   Build a logistic regression model predicting the country a SARS-CoV-2 lineage came from based on its genome\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VJHN3yph4Uy",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "73602f7f-26ce-44f8-f0c8-2738d24443a0"
      },
      "source": [
        "#@title Set up the notebook\n",
        "!pip install Biopython\n",
        "from Bio import SeqIO\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from collections import Counter\n",
        "from sklearn import model_selection, linear_model\n",
        "\n",
        "import gdown\n",
        "data_path = 'https://drive.google.com/uc?id=1f1CtRwSohB7uaAypn8iA4oqdXlD_xXL1'\n",
        "cov2_sequences = 'SARS_CoV_2_sequences_global.fasta'\n",
        "gdown.download(data_path, cov2_sequences, True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Biopython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/02/8b606c4aa92ff61b5eda71d23b499ab1de57d5e818be33f77b01a6f435a8/biopython-1.78-cp36-cp36m-manylinux1_x86_64.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from Biopython) (1.19.4)\n",
            "Installing collected packages: Biopython\n",
            "Successfully installed Biopython-1.78\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'SARS_CoV_2_sequences_global.fasta'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GVs1Qd_iMF3"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPVl67ETxHK5"
      },
      "source": [
        "## Read in and examine the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4jSF-_jw3oz"
      },
      "source": [
        "We are going to read in a set of SARS-CoV-2 genomes from around the world. Note that sequence #0 is the \"reference sequence\"-- one of the original sequences from Wuhan. These global sequences come from the [NCBI database](https://www.ncbi.nlm.nih.gov/labs/virus/vssi/#/virus?SeqType_s=Nucleotide&VirusLineage_ss=SARS-CoV-2,%20taxid:2697049&SLen_i=29000%20TO%2031000&Completeness_s=complete&HostLineage_ss=Homo%20sapiens%20(human),%20taxid:9606).  You can examine the different sequences using the form below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvPJa6Gegnjw",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "760acb37-140c-4b44-ef10-ec2f1263304e"
      },
      "source": [
        "sequences = [r for r in SeqIO.parse(cov2_sequences, 'fasta')]\n",
        "sequence_num =  10#@param {type:\"integer\"}\n",
        "print(sequences[sequence_num])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ID: MT371050\n",
            "Name: MT371050\n",
            "Description: MT371050 |Severe acute respiratory syndrome coronavirus 2 isolate SARS-CoV-2/human/LKA/COV486/2020| complete genome|Sri Lanka\n",
            "Number of features: 0\n",
            "Seq('ATTAAAGGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGATCTCTTGT...AAA')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQdJz8Yyz5t"
      },
      "source": [
        "###**Exercise: How many sequences are there?**\n",
        "\n",
        "Note: Sequences have been uploaded/stored in a variable called ```sequences```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2L6mli7Gyz5u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eedcc62-c2c0-437c-a95f-647a0d43aac8"
      },
      "source": [
        "len(sequences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1538"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6cnVm9ExOGu"
      },
      "source": [
        "###**Exercise: How different are the 1st (non-reference) and 10th SARS-CoV-2 sequences?**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkwJlRubxicM"
      },
      "source": [
        "n = []\n",
        "\n",
        "n = [29903]*1537\n",
        "for i in range(1,1538): #1539\n",
        "  for j in range (len(sequences[i-1])):\n",
        "    if sequences[0][j] == sequences [i][j]:\n",
        "      n[i-1] -= 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwyhB9HQsX8m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0671f692-8ee2-4a11-c48c-abb651addef9"
      },
      "source": [
        "len(n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1537"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHqVhusUxJj6"
      },
      "source": [
        "### **Exercise (BONUS):  Make a histogram of the number of mutations each SARS-CoV-2 sequence has compared to the reference genome.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPF5jWPexNmY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "e479669b-a1f4-4822-afb2-31bde9966c1a"
      },
      "source": [
        "#reference = np.array(sequences[0])\n",
        "## Note: This can take a minute or two to run. Be patient.\n",
        "\n",
        "\n",
        "\n",
        "plt.hist(n)\n",
        "plt.xlabel('# mutations')\n",
        "plt.ylabel('# sequences')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqgCNKdJ2O4l"
      },
      "source": [
        "Interestingly, it looks like there are a couple sequences with a LOT of mutations! We can investigate these sequences a little more.\n",
        "\n",
        "**Examine some of these sequences with high number of mutations by selecting the minimum # of mutations from the form below. What do you notice about the sequences? Discuss with your instructor and peers.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9VSB3eTzJT0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bdc5ef4-3f27-4bab-b6b9-eaea50c744bc"
      },
      "source": [
        "mutations_per_seq = np.array(n)\n",
        "\n",
        "min_number_of_mutations  =  305#@param {type:\"integer\"}\n",
        "idx = np.random.choice(np.where(mutations_per_seq>min_number_of_mutations)[0])\n",
        "print(\"Sequence %i has > %.0f mutations! \\n\" % (idx, min_number_of_mutations))\n",
        "print(sequences[idx], '\\n')\n",
        "print(\"The sequence is composed of: \")\n",
        "Counter(np.array(sequences[idx]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence 822 has > 305 mutations! \n",
            "\n",
            "ID: MT326173\n",
            "Name: MT326173\n",
            "Description: MT326173 |Severe acute respiratory syndrome coronavirus 2 isolate SARS-CoV-2/human/USA/UNKNOWN-UW-1773/2020| complete genome|USA\n",
            "Number of features: 0\n",
            "Seq('------------------------------------------------------...---') \n",
            "\n",
            "The sequence is composed of: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'-': 329, 'A': 8840, 'C': 5422, 'G': 5800, 'N': 7, 'T': 9505})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3_3xSpe20IT"
      },
      "source": [
        "## Missing Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgzI9GyD2h9b"
      },
      "source": [
        "It is hard to see, but some of the sequences have `N` in them. Run the cell below for an example\n",
        "\n",
        "### **Exercise: Calculate the number of sequences that have an ```N``` in them.**\n",
        "\n",
        "**What do you think ```N``` means?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWw4fp1w3MRJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f296e71-dc3e-409d-8810-04230da7ade9"
      },
      "source": [
        "n_sequences_with_N = 0\n",
        "for i in sequences:\n",
        "  for j in i:\n",
        "    if j=='N':\n",
        "      n_sequences_with_N+=1\n",
        "      break\n",
        "print('%i sequences have at least 1 \"N\"!' % n_sequences_with_N)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "326 sequences have at least 1 \"N\"!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eno1YJJo2flS"
      },
      "source": [
        "\n",
        "`N` is not a nucleic acid- it just stands for \"missing\", or \"low quality\". \"Missing\" is different than ```_``` or a deletion. At the locations with ```N```, the sequencing machine had low quality data here, so it was unable to determine what base was at that location. We should remember this when we extact our features. Stay tuned for more on sequencing machines and how sequences are built in the bonus colab of this project!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y4r8Qk64P1n"
      },
      "source": [
        "# Feature Extraction\n",
        "\n",
        "We are going to build a model that predicts the country a SARS-CoV-2 virus came from based on its genome."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD96VzFr65jR"
      },
      "source": [
        "### **Exercise: Recall the structure of machine learning models.** \n",
        "**In general what two categories of data do we need to build a supervised machine learning model? What will we use for each category?**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVJga_xZ_MP4",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08846e1f-ffb1-4968-ca5b-09300247a5a9"
      },
      "source": [
        "_1_  =  'Label' #@param {type:\"string\"}\n",
        "_2_  =  'Inputs' #@param {type:\"string\"}\n",
        "\n",
        "print('1. We need a set of FEATURES (X).\\n',\n",
        "      '  Our features will be the genomes of the different sequences.')\n",
        "print('2. We need LABElS (Y).\\n',\n",
        "      '  Our labels will be the country that each sequence came from.')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1. We need a set of FEATURES (X).\n",
            "   Our features will be the genomes of the different sequences.\n",
            "2. We need LABElS (Y).\n",
            "   Our labels will be the country that each sequence came from.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrHyaErMp9fB"
      },
      "source": [
        "**Question: How will we turn our features into a numeric matrix?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A72g_7uSyVP"
      },
      "source": [
        "## Extract Features (X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3ZU8b4fdXo6"
      },
      "source": [
        "Remember that our input must be a *numeric* matrix/table.\n",
        "We are going to create a matrix where our features are the presence/absence of a specific mutation (given by ```<location>```_```<base>```).  \n",
        "\n",
        "Our columns will be 1_A, 1_T, 3_G, 4_A, etc.\n",
        "\n",
        "\n",
        "| Sequence ID | 1_A | 1_T | 3_G | 4_A  | ...|\n",
        "|-------------|-----|-----|-----|------|----|\n",
        "|Sequence 1   |  1  |  0  |   1 |    0 |  0 |\n",
        "|Sequence 2   |  0  |  0  |   1 |    0 |  0 |\n",
        "|Sequence 3   |  1  |  1  |   0 |    0 |  0 |\n",
        "|Sequence 4   |  0  |  0  |   0 |    1 |  1 |\n",
        "|Sequence 5   |  1  |  0  |   0 |    0 |  1 |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTy_D41nBYe-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "ca03ffb3-6875-43d2-a8c0-111934c6c33d"
      },
      "source": [
        "# Note: This can take a couple minutes to run! \n",
        "# but we can monitor our progress using the tqdm library\n",
        "mutation_df = pd.DataFrame()\n",
        "n_bases_in_seq = len(sequences[0])\n",
        "\n",
        "# Iterate though all positions in this sequence.\n",
        "for location in tqdm.tqdm(range(n_bases_in_seq)): # tqdm is a nice library that prints our progress.\n",
        "  bases_at_location = np.array([s[location] for s in sequences])\n",
        "  # If there are no mutations at this position, move on.\n",
        "  if len(set(bases_at_location))==1: continue # If\n",
        "  for base in ['A', 'T', 'G', 'C', '-']:\n",
        "    feature_values = (bases_at_location==base)\n",
        "    \n",
        "    \n",
        "    # Set the values of any base that equals 'N' to np.nan.\n",
        "    feature_values[bases_at_location=='N'\n",
        "                   ] = np.nan\n",
        "    \n",
        "    # Convert from T/F to 0/1.\n",
        "    feature_values  = feature_values*1\n",
        "    \n",
        "    # Make the column name look like <location>_<base> (1_A, 2_G, 3_A, etc.)\n",
        "    column_name = str(location)+\"-\"+base\n",
        "    mutation_df[column_name] = feature_values\n",
        "\n",
        "# Print the size of the feature matrix/table.\n",
        "n_rows = np.shape(mutation_df)[0]\n",
        "n_columns = np.shape(mutation_df)[1]\n",
        "print(\"Size of matrix: %i rows x %i columns\" %(n_rows, n_columns))\n",
        "\n",
        "# Check what the matrix looks like:\n",
        "mutation_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 29903/29903 [01:17<00:00, 387.26it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Size of matrix: 1538 rows x 12680 columns\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0-A</th>\n",
              "      <th>0-T</th>\n",
              "      <th>0-G</th>\n",
              "      <th>0-C</th>\n",
              "      <th>0--</th>\n",
              "      <th>1-A</th>\n",
              "      <th>1-T</th>\n",
              "      <th>1-G</th>\n",
              "      <th>1-C</th>\n",
              "      <th>1--</th>\n",
              "      <th>2-A</th>\n",
              "      <th>2-T</th>\n",
              "      <th>2-G</th>\n",
              "      <th>2-C</th>\n",
              "      <th>2--</th>\n",
              "      <th>3-A</th>\n",
              "      <th>3-T</th>\n",
              "      <th>3-G</th>\n",
              "      <th>3-C</th>\n",
              "      <th>3--</th>\n",
              "      <th>4-A</th>\n",
              "      <th>4-T</th>\n",
              "      <th>4-G</th>\n",
              "      <th>4-C</th>\n",
              "      <th>4--</th>\n",
              "      <th>5-A</th>\n",
              "      <th>5-T</th>\n",
              "      <th>5-G</th>\n",
              "      <th>5-C</th>\n",
              "      <th>5--</th>\n",
              "      <th>6-A</th>\n",
              "      <th>6-T</th>\n",
              "      <th>6-G</th>\n",
              "      <th>6-C</th>\n",
              "      <th>6--</th>\n",
              "      <th>7-A</th>\n",
              "      <th>7-T</th>\n",
              "      <th>7-G</th>\n",
              "      <th>7-C</th>\n",
              "      <th>7--</th>\n",
              "      <th>...</th>\n",
              "      <th>29895-A</th>\n",
              "      <th>29895-T</th>\n",
              "      <th>29895-G</th>\n",
              "      <th>29895-C</th>\n",
              "      <th>29895--</th>\n",
              "      <th>29896-A</th>\n",
              "      <th>29896-T</th>\n",
              "      <th>29896-G</th>\n",
              "      <th>29896-C</th>\n",
              "      <th>29896--</th>\n",
              "      <th>29897-A</th>\n",
              "      <th>29897-T</th>\n",
              "      <th>29897-G</th>\n",
              "      <th>29897-C</th>\n",
              "      <th>29897--</th>\n",
              "      <th>29898-A</th>\n",
              "      <th>29898-T</th>\n",
              "      <th>29898-G</th>\n",
              "      <th>29898-C</th>\n",
              "      <th>29898--</th>\n",
              "      <th>29899-A</th>\n",
              "      <th>29899-T</th>\n",
              "      <th>29899-G</th>\n",
              "      <th>29899-C</th>\n",
              "      <th>29899--</th>\n",
              "      <th>29900-A</th>\n",
              "      <th>29900-T</th>\n",
              "      <th>29900-G</th>\n",
              "      <th>29900-C</th>\n",
              "      <th>29900--</th>\n",
              "      <th>29901-A</th>\n",
              "      <th>29901-T</th>\n",
              "      <th>29901-G</th>\n",
              "      <th>29901-C</th>\n",
              "      <th>29901--</th>\n",
              "      <th>29902-A</th>\n",
              "      <th>29902-T</th>\n",
              "      <th>29902-G</th>\n",
              "      <th>29902-C</th>\n",
              "      <th>29902--</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 12680 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0-A  0-T  0-G  0-C  0--  ...  29902-A  29902-T  29902-G  29902-C  29902--\n",
              "0    1    0    0    0    0  ...        1        0        0        0        0\n",
              "1    1    0    0    0    0  ...        1        0        0        0        0\n",
              "2    1    0    0    0    0  ...        1        0        0        0        0\n",
              "3    1    0    0    0    0  ...        1        0        0        0        0\n",
              "4    1    0    0    0    0  ...        1        0        0        0        0\n",
              "\n",
              "[5 rows x 12680 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrC_ymFoSs_g"
      },
      "source": [
        "## Extract Label (Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfQVTqPhIYUr"
      },
      "source": [
        "We are going to use the region of the world that each sample came from as the **label**. ![alt text](https://upload.wikimedia.org/wikipedia/commons/3/3d/Flag-map_of_the_world_%282017%29.png)\n",
        "\n",
        "First, let's see how many samples we have from different countries/regions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxL3w1MHFx0k",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67f86501-1abc-4ca7-c8bc-37e2a7e17212"
      },
      "source": [
        "#@title ###**Exercise: Explore the different number of samples that come from each country/region.**\n",
        "country = \"USA\" #@param dict_keys(['China', 'Kazakhstan', 'India', 'Sri Lanka', 'Taiwan', 'Hong Kong', 'Viet Nam', 'Thailand', 'Nepal', 'Israel', 'South Korea', 'Iran', 'Pakistan', 'Turkey', 'Australia', 'USA']\n",
        "countries = [(s.description).split('|')[-1] for s in sequences]\n",
        "print(\"There are %i sequences from %s.\" %\n",
        "      (Counter(countries)[country], country))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1215 sequences from USA.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uu2QZpFdzGG"
      },
      "source": [
        "Since some countries/regions only have a couple samples, we are going to use the geographical **region** of the world as our labels. \n",
        "\n",
        "Since we have a large number of samples from Asia, North America, and Oceania, we will filter ours sequences to just these geographical regions. We will convert our countries/regions to geographical regions using the code below.\n",
        "\n",
        "### **Exercise: Convert each country/region to it's geographical region of the world.** \n",
        "**Use the code below to create a dictionary of ```<country>```:```<region>``` where ```region``` is either ```'Oceania'```, ```'North America'```, or ```'Asia'```, and convert each country/region to geographical region.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODOhep8g8LCB",
        "cellView": "both"
      },
      "source": [
        "countries_to_regions_dict = {\n",
        "         'Australia': 'Oceania',\n",
        "         'China': 'Asia',\n",
        "         'Hong Kong': 'Asia',#### FILL IN ###### ,\n",
        "         'India': 'Asia',#### FILL IN ###### ,\n",
        "         'Nepal': 'Asia',#### FILL IN ###### ,\n",
        "         'South Korea': 'Asia',#### FILL IN ###### ,\n",
        "         'Sri Lanka': 'Asia',#### FILL IN ###### ,\n",
        "         'Taiwan': 'Asia',#### FILL IN ###### ,\n",
        "         'Thailand': 'Asia',#### FILL IN ###### ,\n",
        "         'USA': 'North America',#### FILL IN ###### ,\n",
        "         'Viet Nam': 'Asia'#### FILL IN ###### \n",
        "}\n",
        "\n",
        "regions = [countries_to_regions_dict[c] if c in \n",
        "           countries_to_regions_dict else 'NA' for c in countries]\n",
        "mutation_df['label'] = regions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXuNJGj0K94L"
      },
      "source": [
        "**Now see how many samples there are from each geographical region of the world.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8xUF_S-K809",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c50d5c4f-dcfa-446d-8247-895679c25bc7"
      },
      "source": [
        "region = \"Oceania\" #@param ['Oceania', 'North America', 'Asia']\n",
        "print(\"There are %i sequences from %s.\" %\n",
        "      (Counter(regions)[region], region))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 157 sequences from Oceania.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxVN5LnFLX4X"
      },
      "source": [
        "## Balancing the Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCfkZVGnkCLL"
      },
      "source": [
        "Recall that ML models work the best if we have *balanced* data- a dataset with equal numbers of samples with each label. Run the following code to remove duplicate samples from the dataset, and then balance the samples.\n",
        "\n",
        "### **Exercise: Balance the data equally between samples from Asia, Oceania, and North America**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsGQiLUzL0hI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17557c52-827e-4739-ff0f-6e9a0af13c56"
      },
      "source": [
        "balanced_df = mutation_df.copy()\n",
        "balanced_df['label'] = regions\n",
        "balanced_df = balanced_df[balanced_df.label!='NA']\n",
        "balanced_df = balanced_df.drop_duplicates()\n",
        "samples_north_america = balanced_df[balanced_df.label=='North America']####### FILL IN ####\n",
        "samples_oceania = balanced_df[balanced_df.label=='Oceania'] ##### FILL IN #########\n",
        "samples_asia = balanced_df[balanced_df.label=='Asia'] ##### FILL IN #######\n",
        "\n",
        "# Number of samples we will use from each region.\n",
        "n = min(len(samples_north_america),\n",
        "        len(samples_oceania),\n",
        "        len(samples_asia))\n",
        "        #### FILL IN ######,\n",
        "        ##### FILL IN ####)\n",
        "\n",
        "balanced_df = pd.concat([samples_north_america[:n],\n",
        "                    samples_asia[:n],\n",
        "                    samples_oceania[:n]])\n",
        "print(\"Number of samples in each region: \", Counter(balanced_df['label']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples in each region:  Counter({'North America': 128, 'Asia': 128, 'Oceania': 128})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJBRsrulXnUG"
      },
      "source": [
        "# Logistic Regression Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwZJYgOxQx11"
      },
      "source": [
        "***Congrats!***  We finally are done with preprocessing/cleaning our data! Although tedious, this is an important part of doing machine learning in biology. The data can be complex and messy, and if we don't do some cleaning up beforehand, our models will have poor performance.\n",
        "\n",
        "\n",
        "![](https://media.makeameme.org/created/we-did-it-3b3ac27d2a.jpg)\n",
        "\n",
        "\n",
        "Finally, run the code to set up a ```X``` feature matrix and a ```Y``` label list from our ```balanced_df```. You can explore the different values using the code below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5Ebb7WuO1Oq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "935d0d05-2490-46fe-e8e2-80b9b3260485"
      },
      "source": [
        "X = balanced_df.drop('label', 1)\n",
        "Y = balanced_df.label\n",
        "data = \"X (features)\" #@param ['X (features)', 'Y (label)']\n",
        "start = 1 #@param {type:'integer'}\n",
        "stop =  10#@param {type:'integer'}\n",
        "\n",
        "if start>=stop:print(\"Start must be < stop!\")\n",
        "else:\n",
        "  if data=='X (features)':\n",
        "    print(X.iloc[start:stop])\n",
        "  if data=='Y (label)':\n",
        "    print(Y[start:stop])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     0-A  0-T  0-G  0-C  0--  ...  29902-A  29902-T  29902-G  29902-C  29902--\n",
            "323    1    0    0    0    0  ...        0        0        0        0        1\n",
            "324    0    0    1    0    0  ...        1        0        0        0        0\n",
            "325    1    0    0    0    0  ...        0        0        0        0        1\n",
            "326    1    0    0    0    0  ...        0        0        0        0        1\n",
            "327    0    0    1    0    0  ...        0        0        0        0        1\n",
            "328    1    0    0    0    0  ...        0        0        0        0        1\n",
            "329    1    0    0    0    0  ...        0        0        0        0        1\n",
            "330    1    0    0    0    0  ...        0        0        0        0        1\n",
            "331    1    0    0    0    0  ...        0        0        0        0        1\n",
            "\n",
            "[9 rows x 12680 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4fAOFq3iqFl"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcksFwDLlOsE"
      },
      "source": [
        "We will be using the logistic regression model we have learned about with one modification. We will use the \"multinomial\" class of logistic regression model.  This is used when there are more than 2 categories in the label set. In our case, we have ```Asia```, ```North America```, and ```North America``` as our possible labels.\n",
        "\n",
        "### **Exercise: Train the model using the standard pipeline you have mastered!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbxYkappX6Y6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "838755de-bdae-4995-b4bd-24b141992f39"
      },
      "source": [
        "lm = linear_model.LogisticRegression(\n",
        "    multi_class=\"multinomial\", max_iter=1000,\n",
        "    fit_intercept=False, tol=0.001, solver='saga', random_state=42)\n",
        "\n",
        "# Split into training/testing set. Use a training size of .8\n",
        "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X,Y, train_size = 0.8)#### FILL IN #####\n",
        "\n",
        "# Train/fit model.\n",
        "#### FILL IN ########\n",
        "lm.fit(X_train, Y_train)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=False,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
              "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
              "                   random_state=42, solver='saga', tol=0.001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEoMF1rGisxC"
      },
      "source": [
        "## Testing/Evaluation\n",
        "\n",
        "In addition to printing the accuracy of a model, we can also use a *confusion matrix* to see how well the model performed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXLmY1hfqGT7"
      },
      "source": [
        "###**Exercise: Evaluate the model on the test set.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYGTYPopp5WR",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f676aed-e983-412f-86fe-1369a7798c49"
      },
      "source": [
        "# Predict on the test set.\n",
        "Y_pred = lm.predict(X_test)###### FILL IN #########\n",
        "\n",
        "# Compute accuracy.\n",
        "\n",
        "\n",
        "n = 0 \n",
        "for i in range(Y_pred.shape[0]):\n",
        "  if Y_pred[i] == Y_test.iloc[i]:\n",
        "    n+=1\n",
        "\n",
        "accuracy = n/(Y_pred.shape[0])###### FILL IN #########\n",
        "\n",
        "\n",
        "\n",
        "print(\"Accuracy: %\", accuracy)\n",
        "\n",
        "# Compute confusion matrix.\n",
        "confusion_mat = pd.DataFrame(confusion_matrix(Y_test, Y_pred))\n",
        "confusion_mat.columns = [c + ' predicted' for c in lm.classes_]\n",
        "confusion_mat.index = [c + ' true' for c in lm.classes_]\n",
        "\n",
        "print(confusion_mat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: % 0.9090909090909091\n",
            "                    Asia predicted  North America predicted  Oceania predicted\n",
            "Asia true                       26                        0                  1\n",
            "North America true               3                       22                  2\n",
            "Oceania true                     1                        0                 22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "p8WhinXMr0qK",
        "outputId": "cd1da59f-35da-4761-9866-8c3bfa052029"
      },
      "source": [
        "Y_test.iloc[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Asia'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HwrfLGMKaG4"
      },
      "source": [
        "# Wrapping up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qcebZzBnhVd"
      },
      "source": [
        "![alt text](https://memecrunch.com/meme/60HHF/done-and-done/image.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAgFs2spqoHF"
      },
      "source": [
        "***Great job!*** You built a pretty accurate model that uses genomic data to predict what country a SARS-CoV-2 sample comes from."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsiiqHD5qzOg",
        "cellView": "form"
      },
      "source": [
        "#@title #### **Exercise: To wrap up, write a couple of sentences explaining how your model performed.**\n",
        "Response = \"It was very accurate with about 97% accuracy.\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}